{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>book_link</th>\n",
       "      <th>BookSummary</th>\n",
       "      <th>PublishingHouse</th>\n",
       "      <th>TypeOfBook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>كتاب لغز المنزل رقم في</td>\n",
       "      <td>الكاتب محمود سالم</td>\n",
       "      <td>https://www.arab-books.com/books/%d9%83%d8%aa%...</td>\n",
       "      <td>“وانطلق الجميع إلى شارع النيل. كان صباحًا مشرق...</td>\n",
       "      <td>مؤسسة هنداوي</td>\n",
       "      <td>روايات بوليسية</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>كتاب لغز الموسيقار الصغير</td>\n",
       "      <td>الكاتب محمود سالم</td>\n",
       "      <td>https://www.arab-books.com/books/%d9%83%d8%aa%...</td>\n",
       "      <td>وتابعت نوسة قائلة: الأسبوع الماضي اختطفت العصا...</td>\n",
       "      <td>مؤسسة هنداوي</td>\n",
       "      <td>روايات بوليسية</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>كتاب لغز الوثائق السرية</td>\n",
       "      <td>الكاتب محمود سالم</td>\n",
       "      <td>https://www.arab-books.com/books/%d9%83%d8%aa%...</td>\n",
       "      <td>عندما استيقظ تختخ في اليوم التالي ، كانت تنتظر...</td>\n",
       "      <td>مؤسسة هنداوي</td>\n",
       "      <td>روايات بوليسية</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>كتاب لا تتجاهل</td>\n",
       "      <td>الكاتب هارون يحيىالكاتب هارون يحيى</td>\n",
       "      <td>https://www.arab-books.com/books/%d9%83%d8%aa%...</td>\n",
       "      <td>كتاب لا تتجاهل للكاتب هارون يحيى: منذ اللحظة ا...</td>\n",
       "      <td>عدنان أوكطار</td>\n",
       "      <td>الأدب العربي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>كتاب الحياة في سبيل الله</td>\n",
       "      <td>الكاتب هارون يحيىالكاتب هارون يحيى</td>\n",
       "      <td>https://www.arab-books.com/books/%d9%83%d8%aa%...</td>\n",
       "      <td>كتاب الحياة في سبيل الله للكاتب هارون يحيى: يج...</td>\n",
       "      <td>عدنان أوكطار</td>\n",
       "      <td>اسلامية</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title                              author  \\\n",
       "0     كتاب لغز المنزل رقم في                   الكاتب محمود سالم   \n",
       "1  كتاب لغز الموسيقار الصغير                   الكاتب محمود سالم   \n",
       "2    كتاب لغز الوثائق السرية                   الكاتب محمود سالم   \n",
       "3             كتاب لا تتجاهل  الكاتب هارون يحيىالكاتب هارون يحيى   \n",
       "4   كتاب الحياة في سبيل الله  الكاتب هارون يحيىالكاتب هارون يحيى   \n",
       "\n",
       "                                           book_link  \\\n",
       "0  https://www.arab-books.com/books/%d9%83%d8%aa%...   \n",
       "1  https://www.arab-books.com/books/%d9%83%d8%aa%...   \n",
       "2  https://www.arab-books.com/books/%d9%83%d8%aa%...   \n",
       "3  https://www.arab-books.com/books/%d9%83%d8%aa%...   \n",
       "4  https://www.arab-books.com/books/%d9%83%d8%aa%...   \n",
       "\n",
       "                                         BookSummary PublishingHouse  \\\n",
       "0  “وانطلق الجميع إلى شارع النيل. كان صباحًا مشرق...    مؤسسة هنداوي   \n",
       "1  وتابعت نوسة قائلة: الأسبوع الماضي اختطفت العصا...    مؤسسة هنداوي   \n",
       "2  عندما استيقظ تختخ في اليوم التالي ، كانت تنتظر...    مؤسسة هنداوي   \n",
       "3  كتاب لا تتجاهل للكاتب هارون يحيى: منذ اللحظة ا...    عدنان أوكطار   \n",
       "4  كتاب الحياة في سبيل الله للكاتب هارون يحيى: يج...    عدنان أوكطار   \n",
       "\n",
       "       TypeOfBook  \n",
       "0  روايات بوليسية  \n",
       "1  روايات بوليسية  \n",
       "2  روايات بوليسية  \n",
       "3    الأدب العربي  \n",
       "4         اسلامية  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the dataset from exel sheet\n",
    "df = pd.read_csv('DatasetNLP.csv')\n",
    "# show sample of data set and shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- preprocessing section -----------#\n",
    "# 1- handle null value \n",
    "df['TypeOfBook'].fillna(value=\"مجهول\",inplace=True)\n",
    "df['author'].fillna(value=\"مجهول\",inplace=True)\n",
    "df['PublishingHouse'].fillna(value=\"مجهول\",inplace=True)\n",
    "df['BookSummary'].fillna(value=\" \",inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title              0\n",
       "author             0\n",
       "book_link          0\n",
       "BookSummary        0\n",
       "PublishingHouse    0\n",
       "TypeOfBook         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the data set contains null or not \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df['title'])):\n",
    "    df['title'][i] = re.sub('كتاب','',df['title'][i])\n",
    "    df['author'][i]= re.sub('الكاتب','',df['author'][i])\n",
    "    df['TypeOfBook'][i]= df['TypeOfBook'][i].rstrip()\n",
    "    df['TypeOfBook'][i]= re.sub('^ ','',df['TypeOfBook'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['روايات بوليسية', 'الأدب العربي', 'اسلامية', 'مجهول',\n",
       "       'الفلسفة والمنطق', 'الأدب', 'علوم اللغة', 'العقيدة',\n",
       "       'الأدب اللغة العربية', 'متنوعة', 'أعلام وشخصيات', 'اللغة العربية',\n",
       "       'قصص أطفال', 'العلوم السياسية والاستراتيجية', 'الأطفال',\n",
       "       'القصص القصيرة المترجمة', 'الروايات العالمية المترجمة',\n",
       "       'الثقافة العامة', 'أصول الفقه', 'التاريخ', 'السياسة',\n",
       "       'الخيال العلمي', 'علم النفس', 'روايات عربية', 'تطوير الذات',\n",
       "       'طبية', 'أدب السجون', 'التاريخ القديم', 'الأدب الثقافة العامة',\n",
       "       'البرمجة والتصاميم', ' العقيدة', 'التاريخ الحديث', 'أساطير',\n",
       "       ' روايات بوليسية', 'التنمية الذاتية', 'العلوم الإنسانية', 'تفاسير',\n",
       "       'الجغرافيا', 'علوم القرآن الكريم والسنة النبوية', 'السيرة النبوية',\n",
       "       'فقه المرأة المسلمة', 'الحديث', 'النحو والصرف', 'النقد والبلاغة',\n",
       "       'أدب الرحلات', 'إدارة الأعمال', 'رمضانيات', 'الرياضيات',\n",
       "       'البرمجة والتصاميم الثقافة العامة ما وراء الطبيعة', 'الأحياء الطب',\n",
       "       'الفن', 'الثقافة العامة ما وراء الطبيعة',\n",
       "       'التنمية الذهنية الثقافة العامة',\n",
       "       'التنمية الذهنية الثقافة العامة الطب',\n",
       "       'أعلام وشخصيات العلوم السياسية والاستراتيجية', 'الفيزياء',\n",
       "       'الفيزياء الكيمياء', 'الأحياء', 'الفلك',\n",
       "       'الثقافة العامة العلوم السياسية والاستراتيجية',\n",
       "       'الثقافة العامة الطب', 'الكيمياء', 'علوم الحاسب',\n",
       "       'التاريخ الإسلامي', 'الرياضات المائية والتجديف',\n",
       "       'المسرحيات العالمية المترجمة', 'و دواوين الشعر العربي',\n",
       "       ' الثقافة العامة', ' التنمية الذهنية', ' الحديث', ' أعلام وشخصيات',\n",
       "       ' العلوم السياسية والاستراتيجية', 'مالية واقتصاد',\n",
       "       ' التنمية الذهنية الثقافة العامة', ' الأحياء',\n",
       "       'العقيدة العلوم السياسية والاستراتيجية',\n",
       "       'الأدب العلوم السياسية والاستراتيجية',\n",
       "       'الرد على العلمانية والليبرالية', 'العقيدة القرآن الكريم',\n",
       "       'فتاوي إسلامية', 'المذاهب الإسلامية', 'علوم القرآن',\n",
       "       ' الحديث العقيدة', ' الأدب', 'تاريخ اوروبا',\n",
       "       'القرآن الكريم تفاسير', 'المحاسبة', 'مسرحيات عربية', 'الطب',\n",
       "       'القرآن الكريم', 'الأدب العالمي المترجم', 'تاريخ الأندلس',\n",
       "       'التنمية الذهنية', 'الثقافة العامة الأدب', 'القصص القصيرة',\n",
       "       'تفسير الأحلام', 'تفاسير تفسير الأحلام', 'اسلامية العقيدة',\n",
       "       'شعر مترجم', ' رمضانيات', ' علوم القرآن الكريم والسنة النبوية',\n",
       "       'تعليم برمجة', 'جرافيك ديزاين',\n",
       "       'علوم القرآن الكريم والسنة النبوية القرآن الكريم',\n",
       "       'تفاسير القرآن الكريم علوم القرآن الكريم والسنة النبوية',\n",
       "       'اسلامية القرآن الكريم', 'انجليزية',\n",
       "       'التاريخ القديم الثقافة العامة', 'علم الإجتماع', 'مقارنة الأديان',\n",
       "       'الجريمة', ' قصص أطفال'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TypeOfBook'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "كتب عظم كان كتب هار يحى قصى انس عجب عمل جهز جسم بحث حقق مجر سمو تبع اثر حيء طبع ضؤل حجم صعب رؤت سال كيف تحر شيء كون وجد حتم نظا كامل دهش ثير عنصر نطق أدل عظم وهي بلا شك عظم الل خلق شيء نبع ايت جمل بدع وجد تبر الل احس خلق كتب عظم كان\n",
      "عظم كان\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "import re # Regular expression library\n",
    "import string\n",
    "def remove_stop_words(tokens):\n",
    "    result_tokens =[]\n",
    "    stopwords_list = stopwords.words('arabic')\n",
    "    for token in tokens:\n",
    "        if token not in stopwords_list:\n",
    "            result_tokens.append(token)\n",
    "    return result_tokens\n",
    "# make stemming for arabic word using IRIStemmer\n",
    "def stemming(tokens):\n",
    "    st = ISRIStemmer()\n",
    "    result_tokens=[]\n",
    "    for token in tokens:\n",
    "        result_tokens.append(st.stem(token))\n",
    "    return result_tokens\n",
    "for i in range(len(df['BookSummary'])):\n",
    "    # Remove Punctuation from text\n",
    "    df['BookSummary'][i] = re.sub('[%s]' % re.escape(string.punctuation), '', str(df['BookSummary'][i]))\n",
    "    df['BookSummary'][i] = re.sub('،','',df['BookSummary'][i])\n",
    "    # Remove any digit number from text \n",
    "    df['BookSummary'][i] = re.sub('\\d+','',df['BookSummary'][i])\n",
    "    df['BookSummary'][i] = re.sub('PDF','',df['BookSummary'][i])\n",
    "    # convert text to tokinze \n",
    "    tokens =word_tokenize(str(df['BookSummary'][i]))\n",
    "    tokens_title= word_tokenize(str(df['title'][i]))\n",
    "    # Remove Stop word from text \n",
    "    process_Tokens = remove_stop_words(tokens)\n",
    "    process_Tokens_title = remove_stop_words(tokens_title)\n",
    "    stemming_Tokens =stemming(process_Tokens)\n",
    "    stemming_Tokens_title=stemming(process_Tokens_title)\n",
    "    \n",
    "    # convert tokens to one text \n",
    "    df['BookSummary'][i] =' '.join(stemming_Tokens)\n",
    "    df['title'][i]=' '.join(stemming_Tokens_title)\n",
    "print(df['BookSummary'][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>BookSummary</th>\n",
       "      <th>PublishingHouse</th>\n",
       "      <th>TypeOfBook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>لغز نزل رقم</td>\n",
       "      <td>محمود سالم</td>\n",
       "      <td>“ طلق جمع شرع نيل صبح شرق وسر طول كورنيش جمل و...</td>\n",
       "      <td>مؤسسة هنداوي</td>\n",
       "      <td>روايات بوليسية</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>لغز موسيقار صغر</td>\n",
       "      <td>محمود سالم</td>\n",
       "      <td>تبع نوس قئل سبع اضي خطف عصب طفل اخر نفس طرق مر...</td>\n",
       "      <td>مؤسسة هنداوي</td>\n",
       "      <td>روايات بوليسية</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>لغز وثق سرة</td>\n",
       "      <td>محمود سالم</td>\n",
       "      <td>عند يقظ ختخ اليوم تلي كانت نظر فجأ جدد تصل فتش...</td>\n",
       "      <td>مؤسسة هنداوي</td>\n",
       "      <td>روايات بوليسية</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>جهل</td>\n",
       "      <td>هارون يحيى هارون يحيى</td>\n",
       "      <td>كتب جهل كتب هار يحى لحظ يقظ انس صبح غمس شغل نه...</td>\n",
       "      <td>عدنان أوكطار</td>\n",
       "      <td>الأدب العربي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>حية سبل الل</td>\n",
       "      <td>هارون يحيى هارون يحيى</td>\n",
       "      <td>كتب حية سبل الل كتب هار يحى جهد انس حية حصل كس...</td>\n",
       "      <td>عدنان أوكطار</td>\n",
       "      <td>اسلامية</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             title                  author  \\\n",
       "0      لغز نزل رقم              محمود سالم   \n",
       "1  لغز موسيقار صغر              محمود سالم   \n",
       "2      لغز وثق سرة              محمود سالم   \n",
       "3              جهل   هارون يحيى هارون يحيى   \n",
       "4      حية سبل الل   هارون يحيى هارون يحيى   \n",
       "\n",
       "                                         BookSummary PublishingHouse  \\\n",
       "0  “ طلق جمع شرع نيل صبح شرق وسر طول كورنيش جمل و...    مؤسسة هنداوي   \n",
       "1  تبع نوس قئل سبع اضي خطف عصب طفل اخر نفس طرق مر...    مؤسسة هنداوي   \n",
       "2  عند يقظ ختخ اليوم تلي كانت نظر فجأ جدد تصل فتش...    مؤسسة هنداوي   \n",
       "3  كتب جهل كتب هار يحى لحظ يقظ انس صبح غمس شغل نه...    عدنان أوكطار   \n",
       "4  كتب حية سبل الل كتب هار يحى جهد انس حية حصل كس...    عدنان أوكطار   \n",
       "\n",
       "       TypeOfBook  \n",
       "0  روايات بوليسية  \n",
       "1  روايات بوليسية  \n",
       "2  روايات بوليسية  \n",
       "3    الأدب العربي  \n",
       "4         اسلامية  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features not needed \n",
    "df.drop(['book_link'],axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>BookSummary</th>\n",
       "      <th>PublishingHouse</th>\n",
       "      <th>TypeOfBook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>لغز نزل رقم</td>\n",
       "      <td>79</td>\n",
       "      <td>“ طلق جمع شرع نيل صبح شرق وسر طول كورنيش جمل و...</td>\n",
       "      <td>506</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>لغز موسيقار صغر</td>\n",
       "      <td>79</td>\n",
       "      <td>تبع نوس قئل سبع اضي خطف عصب طفل اخر نفس طرق مر...</td>\n",
       "      <td>506</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>لغز وثق سرة</td>\n",
       "      <td>79</td>\n",
       "      <td>عند يقظ ختخ اليوم تلي كانت نظر فجأ جدد تصل فتش...</td>\n",
       "      <td>506</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>جهل</td>\n",
       "      <td>85</td>\n",
       "      <td>كتب جهل كتب هار يحى لحظ يقظ انس صبح غمس شغل نه...</td>\n",
       "      <td>467</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>حية سبل الل</td>\n",
       "      <td>85</td>\n",
       "      <td>كتب حية سبل الل كتب هار يحى جهد انس حية حصل كس...</td>\n",
       "      <td>467</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             title  author                                        BookSummary  \\\n",
       "0      لغز نزل رقم      79  “ طلق جمع شرع نيل صبح شرق وسر طول كورنيش جمل و...   \n",
       "1  لغز موسيقار صغر      79  تبع نوس قئل سبع اضي خطف عصب طفل اخر نفس طرق مر...   \n",
       "2      لغز وثق سرة      79  عند يقظ ختخ اليوم تلي كانت نظر فجأ جدد تصل فتش...   \n",
       "3              جهل      85  كتب جهل كتب هار يحى لحظ يقظ انس صبح غمس شغل نه...   \n",
       "4      حية سبل الل      85  كتب حية سبل الل كتب هار يحى جهد انس حية حصل كس...   \n",
       "\n",
       "   PublishingHouse  TypeOfBook  \n",
       "0              506          92  \n",
       "1              506          92  \n",
       "2              506          92  \n",
       "3              467          29  \n",
       "4              467          21  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------make label encoder --------------#\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encode_x = LabelEncoder()\n",
    "df['TypeOfBook'] = encode_x.fit_transform(df['TypeOfBook'])\n",
    "df['author'] =encode_x.fit_transform(df['author'])\n",
    "df['PublishingHouse']=encode_x.fit_transform(df['PublishingHouse'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features variables\n",
    "x = df[['title','author','BookSummary','PublishingHouse']]\n",
    "# target variables\n",
    "y = df['TypeOfBook']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6428, 14434)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np \n",
    "import scipy as sp\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "\n",
    "\n",
    "# ------------ extract features -----------#\n",
    "train_title_vectorizer = TfidfVectorizer()\n",
    "train_BookSummary_vectorizer = TfidfVectorizer()\n",
    "\n",
    "train_title_features = train_title_vectorizer.fit_transform(x['title'])\n",
    "train_BookSummary = train_BookSummary_vectorizer.fit_transform(x['BookSummary'])\n",
    "\n",
    "x=hstack((np.array(x['author'])[:,None],\n",
    "          np.array(x['PublishingHouse'])[:,None],\n",
    "          train_BookSummary,train_title_features))\n",
    "\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 5 0 0]\n",
      " ...\n",
      " [0 0 2 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00        17\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         6\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00        24\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00        13\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         3\n",
      "          17       0.00      0.00      0.00        14\n",
      "          18       0.00      0.00      0.00         5\n",
      "          20       0.00      0.00      0.00         5\n",
      "          21       0.64      0.77      0.70       593\n",
      "          22       0.00      0.00      0.00         1\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.00      0.00      0.00         1\n",
      "          26       0.78      0.42      0.55        73\n",
      "          27       0.00      0.00      0.00         1\n",
      "          28       0.00      0.00      0.00         8\n",
      "          29       0.34      0.31      0.32       193\n",
      "          30       0.67      1.00      0.80         2\n",
      "          31       0.00      0.00      0.00         1\n",
      "          32       1.00      0.99      0.99        95\n",
      "          33       0.00      0.00      0.00         3\n",
      "          35       0.38      0.33      0.35        52\n",
      "          36       0.56      0.31      0.40        29\n",
      "          37       0.00      0.00      0.00        15\n",
      "          38       0.17      0.16      0.16        19\n",
      "          40       0.43      0.35      0.39        17\n",
      "          41       0.00      0.00      0.00         2\n",
      "          44       0.83      0.49      0.62        49\n",
      "          46       0.00      0.00      0.00         1\n",
      "          48       0.00      0.00      0.00         1\n",
      "          50       1.00      0.50      0.67         6\n",
      "          51       0.71      0.90      0.80        39\n",
      "          52       0.00      0.00      0.00         6\n",
      "          53       0.50      1.00      0.67         1\n",
      "          54       0.17      0.09      0.12        98\n",
      "          55       0.00      0.00      0.00         1\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00         5\n",
      "          58       0.17      0.11      0.13        19\n",
      "          59       1.00      0.86      0.92        14\n",
      "          60       0.41      0.40      0.41       119\n",
      "          62       0.00      0.00      0.00         1\n",
      "          64       0.80      0.27      0.40        15\n",
      "          65       0.27      0.12      0.17        32\n",
      "          66       0.00      0.00      0.00         1\n",
      "          67       0.00      0.00      0.00         1\n",
      "          68       0.00      0.00      0.00         1\n",
      "          70       0.69      0.80      0.74        30\n",
      "          71       0.74      0.95      0.83        21\n",
      "          72       0.00      0.00      0.00         4\n",
      "          73       1.00      0.87      0.93        31\n",
      "          75       0.00      0.00      0.00         8\n",
      "          76       1.00      0.60      0.75         5\n",
      "          77       0.00      0.00      0.00         2\n",
      "          78       0.00      0.00      0.00        10\n",
      "          79       0.00      0.00      0.00         4\n",
      "          80       0.00      0.00      0.00         1\n",
      "          82       0.33      0.50      0.40         2\n",
      "          83       0.00      0.00      0.00         2\n",
      "          84       0.00      0.00      0.00         0\n",
      "          85       1.00      0.33      0.50         9\n",
      "          86       0.62      0.48      0.55        31\n",
      "          89       0.00      0.00      0.00         2\n",
      "          91       0.87      0.83      0.85        64\n",
      "          92       0.87      0.89      0.88       254\n",
      "          93       0.42      0.66      0.52       332\n",
      "          94       0.00      0.00      0.00         1\n",
      "          95       0.00      0.00      0.00         3\n",
      "          96       0.00      0.00      0.00         1\n",
      "          97       0.92      0.92      0.92        37\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.18      0.17      0.17        12\n",
      "         100       0.00      0.00      0.00         2\n",
      "         101       0.00      0.00      0.00         3\n",
      "         102       0.00      0.00      0.00         1\n",
      "         103       0.00      0.00      0.00         2\n",
      "         104       0.00      0.00      0.00         5\n",
      "         105       0.58      0.79      0.67        14\n",
      "         106       0.00      0.00      0.00         3\n",
      "         107       0.14      0.04      0.06        25\n",
      "         108       0.69      0.42      0.52        26\n",
      "         109       0.00      0.00      0.00        11\n",
      "         110       0.00      0.00      0.00         1\n",
      "         111       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.57      2572\n",
      "   macro avg       0.23      0.20      0.20      2572\n",
      "weighted avg       0.55      0.57      0.55      2572\n",
      "\n",
      "0.5703732503888025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahmoud0020\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mahmoud0020\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# ----------randomForest model -------------#\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=11)\n",
    "classifier.fit(x_train, y_train) \n",
    "from sklearn import metrics \n",
    "predictions = classifier.predict(x_test)\n",
    "print(metrics.confusion_matrix(y_test,predictions))\n",
    "print(metrics.classification_report(y_test,predictions))\n",
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00        17\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         6\n",
      "           6       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00        24\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00        13\n",
      "          16       0.00      0.00      0.00         3\n",
      "          17       0.00      0.00      0.00        14\n",
      "          18       0.00      0.00      0.00         5\n",
      "          20       0.00      0.00      0.00         5\n",
      "          21       0.31      0.98      0.47       593\n",
      "          22       0.00      0.00      0.00         1\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.00      0.00      0.00         1\n",
      "          26       0.00      0.00      0.00        73\n",
      "          27       0.00      0.00      0.00         1\n",
      "          28       0.00      0.00      0.00         8\n",
      "          29       0.20      0.01      0.02       193\n",
      "          30       0.00      0.00      0.00         2\n",
      "          31       0.00      0.00      0.00         1\n",
      "          32       1.00      0.99      0.99        95\n",
      "          33       0.00      0.00      0.00         3\n",
      "          35       0.00      0.00      0.00        52\n",
      "          36       0.00      0.00      0.00        29\n",
      "          37       0.00      0.00      0.00        15\n",
      "          38       0.00      0.00      0.00        19\n",
      "          40       0.00      0.00      0.00        17\n",
      "          41       0.00      0.00      0.00         2\n",
      "          44       0.86      0.12      0.21        49\n",
      "          46       0.00      0.00      0.00         1\n",
      "          48       0.00      0.00      0.00         1\n",
      "          50       0.00      0.00      0.00         6\n",
      "          51       0.00      0.00      0.00        39\n",
      "          52       0.00      0.00      0.00         6\n",
      "          53       0.00      0.00      0.00         1\n",
      "          54       0.00      0.00      0.00        98\n",
      "          55       0.00      0.00      0.00         1\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00         5\n",
      "          58       0.00      0.00      0.00        19\n",
      "          59       0.00      0.00      0.00        14\n",
      "          60       1.00      0.03      0.07       119\n",
      "          62       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00        15\n",
      "          65       0.00      0.00      0.00        32\n",
      "          66       0.00      0.00      0.00         1\n",
      "          67       0.00      0.00      0.00         1\n",
      "          68       0.00      0.00      0.00         1\n",
      "          70       0.00      0.00      0.00        30\n",
      "          71       0.00      0.00      0.00        21\n",
      "          72       0.00      0.00      0.00         4\n",
      "          73       0.00      0.00      0.00        31\n",
      "          75       0.00      0.00      0.00         8\n",
      "          76       0.00      0.00      0.00         5\n",
      "          77       0.00      0.00      0.00         2\n",
      "          78       0.00      0.00      0.00        10\n",
      "          79       0.00      0.00      0.00         4\n",
      "          80       0.00      0.00      0.00         1\n",
      "          82       0.00      0.00      0.00         2\n",
      "          83       0.00      0.00      0.00         2\n",
      "          85       0.00      0.00      0.00         9\n",
      "          86       0.00      0.00      0.00        31\n",
      "          89       0.00      0.00      0.00         2\n",
      "          91       0.44      0.95      0.60        64\n",
      "          92       1.00      0.35      0.51       254\n",
      "          93       0.53      0.58      0.56       332\n",
      "          94       0.00      0.00      0.00         1\n",
      "          95       0.00      0.00      0.00         3\n",
      "          96       0.00      0.00      0.00         1\n",
      "          97       0.00      0.00      0.00        37\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.00      0.00      0.00        12\n",
      "         100       0.00      0.00      0.00         2\n",
      "         101       0.00      0.00      0.00         3\n",
      "         102       0.00      0.00      0.00         1\n",
      "         103       0.00      0.00      0.00         2\n",
      "         104       0.00      0.00      0.00         5\n",
      "         105       0.00      0.00      0.00        14\n",
      "         106       0.00      0.00      0.00         3\n",
      "         107       0.00      0.00      0.00        25\n",
      "         108       0.00      0.00      0.00        26\n",
      "         109       0.00      0.00      0.00        11\n",
      "         110       0.00      0.00      0.00         1\n",
      "         111       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.40      2572\n",
      "   macro avg       0.06      0.05      0.04      2572\n",
      "weighted avg       0.37      0.40      0.29      2572\n",
      "\n",
      "0.39930015552099535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahmoud0020\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mahmoud0020\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mahmoud0020\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# ----------- logistic regression model -----------#\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model = LogisticRegression(solver='lbfgs',max_iter=1000)\n",
    "lr_model.fit(x_train,y_train)\n",
    "predictions = lr_model.predict(x_test)\n",
    "from sklearn import metrics \n",
    "print(metrics.confusion_matrix(y_test,predictions))\n",
    "print(metrics.classification_report(y_test,predictions))\n",
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
